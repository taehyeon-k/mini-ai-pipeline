{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "487badb2-2a7d-404f-ad54-597a41186d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab') \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4048ae49-259e-4714-a6ef-dd490ceba5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full HF dataset size: 6000\n",
      "Subset size: 2500\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "hf_full = load_dataset(\"jxie/flickr8k\", split=\"train\")  \n",
    "\n",
    "print(\"Full HF dataset size:\", len(hf_full))\n",
    "\n",
    "hf_500 = hf_full.shuffle(seed=42).select(range(2500))\n",
    "print(\"Subset size:\", len(hf_500))\n",
    "\n",
    "split1 = hf_500.train_test_split(test_size=0.3, seed=42)\n",
    "hf_train = split1[\"train\"]\n",
    "hf_temp = split1[\"test\"]\n",
    "\n",
    "split2 = hf_temp.train_test_split(test_size=0.5, seed=42)\n",
    "hf_val = split2[\"train\"]\n",
    "hf_test = split2[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bad2ef9a-ac69-4073-a9ad-021e214ef8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train len: 1750 Val len: 375 Test len: 375\n"
     ]
    }
   ],
   "source": [
    "class HFImageCaptionDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, transform=None, use_all_captions=False):\n",
    "        self.hf_dataset = hf_dataset\n",
    "        self.transform = transform\n",
    "        self.use_all_captions = use_all_captions\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hf_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.hf_dataset[idx]\n",
    "        image = example[\"image\"]  \n",
    "\n",
    "        if self.use_all_captions:\n",
    "            captions = [example[f\"caption_{i}\"] for i in range(5)]\n",
    "        else:\n",
    "            captions = example[\"caption_0\"]  \n",
    "\n",
    "        if self.transform is not None:\n",
    "            image_out = self.transform(image)  \n",
    "        else:\n",
    "            image_out = image  \n",
    "\n",
    "        sample_id = idx\n",
    "        return image_out, captions, sample_id\n",
    "\n",
    "\n",
    "baseline_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = HFImageCaptionDataset(hf_train, transform=baseline_transform, use_all_captions=True)\n",
    "val_dataset   = HFImageCaptionDataset(hf_val,   transform=baseline_transform, use_all_captions=True)\n",
    "test_dataset  = HFImageCaptionDataset(hf_test,  transform=baseline_transform, use_all_captions=True)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "print(\"Train len:\", len(train_dataset), \"Val len:\", len(val_dataset), \"Test len:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "407452b3-b001-43f2-93bc-861527db24f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_fn = SmoothingFunction().method1\n",
    "def compute_bleu_scores(reference_texts, predicted_text):\n",
    "    if isinstance(reference_texts, str):\n",
    "        reference_texts = [reference_texts]\n",
    "\n",
    "    refs_tokenized = [\n",
    "        nltk.word_tokenize(ref.lower()) for ref in reference_texts\n",
    "    ]\n",
    "    pred_tokens = nltk.word_tokenize(predicted_text.lower())\n",
    "\n",
    "    bleu1 = sentence_bleu(\n",
    "        refs_tokenized,\n",
    "        pred_tokens,\n",
    "        weights=(1.0, 0.0, 0.0, 0.0),\n",
    "        smoothing_function=smooth_fn,\n",
    "    )\n",
    "    bleu2 = sentence_bleu(\n",
    "        refs_tokenized,\n",
    "        pred_tokens,\n",
    "        weights=(0.5, 0.5, 0.0, 0.0),\n",
    "        smoothing_function=smooth_fn,\n",
    "    )\n",
    "    return bleu1, bleu2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "04911e99-f597-4263-b299-e364306ce466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_simple_features(image_tensor):\n",
    "    if not torch.is_floating_point(image_tensor):\n",
    "        image_tensor = image_tensor.float() / 255.0\n",
    "\n",
    "    C, H, W = image_tensor.shape\n",
    "\n",
    "    brightness = image_tensor.mean().item()\n",
    "\n",
    "    channel_means = image_tensor.view(C, -1).mean(dim=1)  \n",
    "    total = channel_means.sum() + 1e-8\n",
    "    channel_ratios = channel_means / total\n",
    "\n",
    "    colors = [\"r\", \"g\", \"b\"]\n",
    "    dominant_idx = int(torch.argmax(channel_ratios))\n",
    "    dominant_channel = colors[dominant_idx]\n",
    "\n",
    "    if channel_ratios[dominant_idx] < 0.4:\n",
    "        dominant_channel = \"none\"\n",
    "\n",
    "    gray = image_tensor.mean(dim=0, keepdim=True) \n",
    "\n",
    "    gx = gray[:, :, 1:] - gray[:, :, :-1]  \n",
    "    gy = gray[:, 1:, :] - gray[:, :-1, :] \n",
    "\n",
    "    gx = F.pad(gx, (0, 1, 0, 0))\n",
    "    gy = F.pad(gy, (0, 0, 0, 1))\n",
    "\n",
    "    edge_mag = torch.sqrt(gx ** 2 + gy ** 2) \n",
    "    edge_density = (edge_mag > 0.1).float().mean().item()\n",
    "\n",
    "    return {\n",
    "        \"brightness\": brightness,\n",
    "        \"dominant_channel\": dominant_channel,\n",
    "        \"edge_density\": edge_density,\n",
    "    }\n",
    "\n",
    "\n",
    "def naive_baseline_caption(image_tensor):\n",
    "    feats = extract_simple_features(image_tensor)\n",
    "    b = feats[\"brightness\"]\n",
    "    d = feats[\"dominant_channel\"]\n",
    "    e = feats[\"edge_density\"]\n",
    "\n",
    "    if b < 0.25:\n",
    "        if e > 0.15:\n",
    "            return \"A dark scene with many shapes and edges.\"\n",
    "        else:\n",
    "            return \"A dark scene with a few bright regions.\"\n",
    "\n",
    "    elif b > 0.65:\n",
    "        if d == \"b\":\n",
    "            if e < 0.12:\n",
    "                return \"A bright outdoor scene with a lot of blue sky.\"\n",
    "            else:\n",
    "                return \"A bright outdoor scene with blue tones and many objects.\"\n",
    "        elif d == \"g\":\n",
    "            return \"A bright outdoor scene with green vegetation.\"\n",
    "        elif d == \"r\":\n",
    "            return \"A bright scene with a warm-colored object in view.\"\n",
    "        else:  \n",
    "            if e > 0.2:\n",
    "                return \"A bright scene with many detailed objects.\"\n",
    "            else:\n",
    "                return \"A bright scene with a few large regions.\"\n",
    "\n",
    "    else:\n",
    "        if d == \"g\":\n",
    "            return \"A moderately lit scene with some greenery.\"\n",
    "        elif d == \"b\":\n",
    "            if e > 0.18:\n",
    "                return \"A scene with blue tones and several objects.\"\n",
    "            else:\n",
    "                return \"A calm scene with some blue regions.\"\n",
    "        elif d == \"r\":\n",
    "            return \"A scene with noticeable warm colors and moderate lighting.\"\n",
    "        else:  \n",
    "            if e > 0.2:\n",
    "                return \"A busy scene with many edges and details.\"\n",
    "            else:\n",
    "                return \"A simple scene with a few large regions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f5366275-bc94-4e50-a24a-7caab0469f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive baseline mean BLEU-1: 0.39585358993441616\n",
      "Naive baseline mean BLEU-2: 0.10649451853917476\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>gt_caption</th>\n",
       "      <th>pred_caption</th>\n",
       "      <th>bleu1</th>\n",
       "      <th>bleu2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(A child holding onto handles sliding across a...</td>\n",
       "      <td>A busy scene with many edges and details.</td>\n",
       "      <td>0.298280</td>\n",
       "      <td>0.057762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>(A bearded man is sitting on a bench wearing a...</td>\n",
       "      <td>A busy scene with many edges and details.</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.064550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>(A girl with black gloves is running ., Two gi...</td>\n",
       "      <td>A simple scene with a few large regions.</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.074536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>(A boy in a blue wetsuit is riding a surfboard...</td>\n",
       "      <td>A calm scene with some blue regions.</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.073193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>(A chubby or buff kid in shorts is holding on ...</td>\n",
       "      <td>A dark scene with a few bright regions.</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.074536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id                                         gt_caption  \\\n",
       "0          0  (A child holding onto handles sliding across a...   \n",
       "1          8  (A bearded man is sitting on a bench wearing a...   \n",
       "2         16  (A girl with black gloves is running ., Two gi...   \n",
       "3         24  (A boy in a blue wetsuit is riding a surfboard...   \n",
       "4         32  (A chubby or buff kid in shorts is holding on ...   \n",
       "\n",
       "                                pred_caption     bleu1     bleu2  \n",
       "0  A busy scene with many edges and details.  0.298280  0.057762  \n",
       "1  A busy scene with many edges and details.  0.333333  0.064550  \n",
       "2   A simple scene with a few large regions.  0.444444  0.074536  \n",
       "3       A calm scene with some blue regions.  0.375000  0.073193  \n",
       "4    A dark scene with a few bright regions.  0.444444  0.074536  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "baseline_results = []\n",
    "\n",
    "for image_tensor, gt_caption, sample_id in test_loader:\n",
    "    image_tensor = image_tensor[0] \n",
    "\n",
    "    pred_caption = naive_baseline_caption(image_tensor)\n",
    "    bleu1, bleu2 = compute_bleu_scores(gt_caption[0], pred_caption)\n",
    "\n",
    "    baseline_results.append({\n",
    "        \"sample_id\": int(sample_id[0].item()) if isinstance(sample_id[0], torch.Tensor) else int(sample_id[0]),\n",
    "        \"gt_caption\": gt_caption[0],\n",
    "        \"pred_caption\": pred_caption,\n",
    "        \"bleu1\": bleu1,\n",
    "        \"bleu2\": bleu2,\n",
    "    })\n",
    "\n",
    "baseline_df = pd.DataFrame(baseline_results)\n",
    "print(\"Naive baseline mean BLEU-1:\", baseline_df[\"bleu1\"].mean())\n",
    "print(\"Naive baseline mean BLEU-2:\", baseline_df[\"bleu2\"].mean())\n",
    "baseline_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fa3a3357-65bb-4a51-b66e-2ff339132f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def blip_generate_caption(pil_image, max_length=20, num_beams=3):\n",
    "    \"\"\"\n",
    "    pil_image: PIL.Image in RGB\n",
    "    Returns: caption string\n",
    "    \"\"\"\n",
    "    inputs = processor(images=pil_image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    output_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_length=max_length,\n",
    "        num_beams=num_beams\n",
    "    )\n",
    "    caption = processor.decode(output_ids[0], skip_special_tokens=True)\n",
    "    return caption.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd20b536-ea4e-4f8f-ab81-5becd26bc649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d357f9ad1b4f4a0dbbec166bd0d26e5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI pipeline mean BLEU-1: 0.5601613623240005\n",
      "AI pipeline mean BLEU-2: 0.4091202389465279\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>gt_caption</th>\n",
       "      <th>pred_caption</th>\n",
       "      <th>bleu1</th>\n",
       "      <th>bleu2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[A child holding onto handles sliding across a...</td>\n",
       "      <td>a man jumping in the air</td>\n",
       "      <td>0.256709</td>\n",
       "      <td>0.162357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[A brown dog is running through tall green gra...</td>\n",
       "      <td>a dog running through a field of tall grass</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.935414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[A lonely skier enjoys the slopes on a beautif...</td>\n",
       "      <td>the sky is clear</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.091287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[A greyhound in a race wearing a metal muzzle ...</td>\n",
       "      <td>the dog is white</td>\n",
       "      <td>0.286505</td>\n",
       "      <td>0.052308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[A cyclist is leaning his bicycle up on its fr...</td>\n",
       "      <td>a man doing a trick on a bike</td>\n",
       "      <td>0.778801</td>\n",
       "      <td>0.721029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id                                         gt_caption  \\\n",
       "0          0  [A child holding onto handles sliding across a...   \n",
       "1          1  [A brown dog is running through tall green gra...   \n",
       "2          2  [A lonely skier enjoys the slopes on a beautif...   \n",
       "3          3  [A greyhound in a race wearing a metal muzzle ...   \n",
       "4          4  [A cyclist is leaning his bicycle up on its fr...   \n",
       "\n",
       "                                  pred_caption     bleu1     bleu2  \n",
       "0                     a man jumping in the air  0.256709  0.162357  \n",
       "1  a dog running through a field of tall grass  1.000000  0.935414  \n",
       "2                             the sky is clear  0.250000  0.091287  \n",
       "3                             the dog is white  0.286505  0.052308  \n",
       "4                a man doing a trick on a bike  0.778801  0.721029  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_results = []\n",
    "\n",
    "MODEL_NAME = \"Salesforce/blip-image-captioning-base\"\n",
    "processor = BlipProcessor.from_pretrained(MODEL_NAME)\n",
    "model = BlipForConditionalGeneration.from_pretrained(MODEL_NAME).to(device)\n",
    "model.eval()\n",
    "\n",
    "pil_test_dataset = HFImageCaptionDataset(hf_test, transform=None, use_all_captions=True)\n",
    "\n",
    "pil_test_loader = DataLoader(\n",
    "    pil_test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    collate_fn=lambda batch: batch[0], \n",
    ")\n",
    "\n",
    "for pil_image, gt_caption, sample_id in tqdm(pil_test_loader):\n",
    "    sid = int(sample_id)\n",
    "\n",
    "    pred_caption = blip_generate_caption(pil_image)\n",
    "    bleu1, bleu2 = compute_bleu_scores(gt_caption, pred_caption)\n",
    "\n",
    "    ai_results.append({\n",
    "        \"sample_id\": sid,\n",
    "        \"gt_caption\": gt_caption,\n",
    "        \"pred_caption\": pred_caption,\n",
    "        \"bleu1\": bleu1,\n",
    "        \"bleu2\": bleu2,\n",
    "    })\n",
    "\n",
    "ai_df = pd.DataFrame(ai_results)\n",
    "print(\"AI pipeline mean BLEU-1:\", ai_df[\"bleu1\"].mean())\n",
    "print(\"AI pipeline mean BLEU-2:\", ai_df[\"bleu2\"].mean())\n",
    "ai_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e947759-44a3-459d-a84e-ec8398b8744b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Overall Mean Scores ===\n",
      "Baseline BLEU-1: 0.39585358993441616\n",
      "Baseline BLEU-2: 0.10649451853917476\n",
      "AI BLEU-1: 0.5554942828753789\n",
      "AI BLEU-2: 0.3979549488340454\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>gt_caption_baseline</th>\n",
       "      <th>pred_caption_baseline</th>\n",
       "      <th>bleu1_baseline</th>\n",
       "      <th>bleu2_baseline</th>\n",
       "      <th>gt_caption_ai</th>\n",
       "      <th>pred_caption_ai</th>\n",
       "      <th>bleu1_ai</th>\n",
       "      <th>bleu2_ai</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>(A child holding onto handles sliding across a...</td>\n",
       "      <td>A busy scene with many edges and details.</td>\n",
       "      <td>0.298280</td>\n",
       "      <td>0.057762</td>\n",
       "      <td>[A child holding onto handles sliding across a...</td>\n",
       "      <td>a man jumping in the air</td>\n",
       "      <td>0.256709</td>\n",
       "      <td>0.162357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>(A bearded man is sitting on a bench wearing a...</td>\n",
       "      <td>A busy scene with many edges and details.</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.064550</td>\n",
       "      <td>[A bearded man is sitting on a bench wearing a...</td>\n",
       "      <td>man sitting on a park bench</td>\n",
       "      <td>0.427848</td>\n",
       "      <td>0.296422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>(A girl with black gloves is running ., Two gi...</td>\n",
       "      <td>A simple scene with a few large regions.</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.074536</td>\n",
       "      <td>[A girl with black gloves is running ., A woma...</td>\n",
       "      <td>a woman wearing a purple shirt</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.577350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>(A boy in a blue wetsuit is riding a surfboard...</td>\n",
       "      <td>A calm scene with some blue regions.</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.073193</td>\n",
       "      <td>[A boy in a blue wetsuit is riding a surfboard...</td>\n",
       "      <td>two people in the water</td>\n",
       "      <td>0.536256</td>\n",
       "      <td>0.423948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>(A chubby or buff kid in shorts is holding on ...</td>\n",
       "      <td>A dark scene with a few bright regions.</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.074536</td>\n",
       "      <td>[A chubby or buff kid in shorts is holding on ...</td>\n",
       "      <td>a little boy standing on a rug</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.308607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>40</td>\n",
       "      <td>(A brown dog digging a hole ., A kayaker goes ...</td>\n",
       "      <td>A busy scene with many edges and details.</td>\n",
       "      <td>0.198853</td>\n",
       "      <td>0.047162</td>\n",
       "      <td>[A brown dog digging a hole ., A brown dog dig...</td>\n",
       "      <td>a dog digging a hole in the ground</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48</td>\n",
       "      <td>(A child stoops to pick up a watermelon from a...</td>\n",
       "      <td>A dark scene with a few bright regions.</td>\n",
       "      <td>0.398073</td>\n",
       "      <td>0.267035</td>\n",
       "      <td>[A child stoops to pick up a watermelon from a...</td>\n",
       "      <td>a little girl standing in front of a pile of w...</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.603023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>56</td>\n",
       "      <td>(many people look over the side of a bridge .,...</td>\n",
       "      <td>A simple scene with a few large regions.</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>[many people look over the side of a bridge .,...</td>\n",
       "      <td>a group of people standing on a bridge over a ...</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.797724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64</td>\n",
       "      <td>(A black and brown dog is laying on a white sh...</td>\n",
       "      <td>A simple scene with a few large regions.</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>[A black and brown dog is laying on a white sh...</td>\n",
       "      <td>the dog is black and brown</td>\n",
       "      <td>0.505442</td>\n",
       "      <td>0.428882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>72</td>\n",
       "      <td>(A black dog carries a huge stick in its mouth...</td>\n",
       "      <td>A bright scene with a few large regions.</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.064550</td>\n",
       "      <td>[A black dog carries a huge stick in its mouth...</td>\n",
       "      <td>a dog running in the snow</td>\n",
       "      <td>0.427848</td>\n",
       "      <td>0.363041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id                                gt_caption_baseline  \\\n",
       "0          0  (A child holding onto handles sliding across a...   \n",
       "1          8  (A bearded man is sitting on a bench wearing a...   \n",
       "2         16  (A girl with black gloves is running ., Two gi...   \n",
       "3         24  (A boy in a blue wetsuit is riding a surfboard...   \n",
       "4         32  (A chubby or buff kid in shorts is holding on ...   \n",
       "5         40  (A brown dog digging a hole ., A kayaker goes ...   \n",
       "6         48  (A child stoops to pick up a watermelon from a...   \n",
       "7         56  (many people look over the side of a bridge .,...   \n",
       "8         64  (A black and brown dog is laying on a white sh...   \n",
       "9         72  (A black dog carries a huge stick in its mouth...   \n",
       "\n",
       "                       pred_caption_baseline  bleu1_baseline  bleu2_baseline  \\\n",
       "0  A busy scene with many edges and details.        0.298280        0.057762   \n",
       "1  A busy scene with many edges and details.        0.333333        0.064550   \n",
       "2   A simple scene with a few large regions.        0.444444        0.074536   \n",
       "3       A calm scene with some blue regions.        0.375000        0.073193   \n",
       "4    A dark scene with a few bright regions.        0.444444        0.074536   \n",
       "5  A busy scene with many edges and details.        0.198853        0.047162   \n",
       "6    A dark scene with a few bright regions.        0.398073        0.267035   \n",
       "7   A simple scene with a few large regions.        0.444444        0.235702   \n",
       "8   A simple scene with a few large regions.        0.444444        0.235702   \n",
       "9   A bright scene with a few large regions.        0.333333        0.064550   \n",
       "\n",
       "                                       gt_caption_ai  \\\n",
       "0  [A child holding onto handles sliding across a...   \n",
       "1  [A bearded man is sitting on a bench wearing a...   \n",
       "2  [A girl with black gloves is running ., A woma...   \n",
       "3  [A boy in a blue wetsuit is riding a surfboard...   \n",
       "4  [A chubby or buff kid in shorts is holding on ...   \n",
       "5  [A brown dog digging a hole ., A brown dog dig...   \n",
       "6  [A child stoops to pick up a watermelon from a...   \n",
       "7  [many people look over the side of a bridge .,...   \n",
       "8  [A black and brown dog is laying on a white sh...   \n",
       "9  [A black dog carries a huge stick in its mouth...   \n",
       "\n",
       "                                     pred_caption_ai  bleu1_ai  bleu2_ai  \n",
       "0                           a man jumping in the air  0.256709  0.162357  \n",
       "1                        man sitting on a park bench  0.427848  0.296422  \n",
       "2                     a woman wearing a purple shirt  0.833333  0.577350  \n",
       "3                            two people in the water  0.536256  0.423948  \n",
       "4                     a little boy standing on a rug  0.571429  0.308607  \n",
       "5                 a dog digging a hole in the ground  0.875000  0.866025  \n",
       "6  a little girl standing in front of a pile of w...  0.727273  0.603023  \n",
       "7  a group of people standing on a bridge over a ...  0.909091  0.797724  \n",
       "8                         the dog is black and brown  0.505442  0.428882  \n",
       "9                          a dog running in the snow  0.427848  0.363041  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "merged_df = baseline_df.merge(\n",
    "    ai_df,\n",
    "    on=\"sample_id\",\n",
    "    suffixes=(\"_baseline\", \"_ai\"),\n",
    ")\n",
    "\n",
    "print(\"=== Overall Mean Scores ===\")\n",
    "print(\"Baseline BLEU-1:\", merged_df[\"bleu1_baseline\"].mean())\n",
    "print(\"Baseline BLEU-2:\", merged_df[\"bleu2_baseline\"].mean())\n",
    "print(\"AI BLEU-1:\", merged_df[\"bleu1_ai\"].mean())\n",
    "print(\"AI BLEU-2:\", merged_df[\"bleu2_ai\"].mean())\n",
    "\n",
    "merged_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8733fe3e-b969-49c7-a799-b10906ea5bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('A brown dog digging a hole .',\n",
       "  'A kayaker goes through the waves holding his paddle .',\n",
       "  'The men are climbing .',\n",
       "  'A child in a red jacket holding up two fingers .',\n",
       "  'A child in a red jacket jumping off of a rock into sand .',\n",
       "  'A group of people stand in the snow in a mountain .',\n",
       "  'A security man guards the door as another one brings his items off .',\n",
       "  'A little dog carries a small stick in his mouth .'),\n",
       " 'A busy scene with many edges and details.',\n",
       " 'a dog digging a hole in the ground')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 5\n",
    "merged_df.iloc[idx]['gt_caption_baseline'], merged_df.iloc[idx]['pred_caption_baseline'], merged_df.iloc[idx]['pred_caption_ai']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "607ea81c-bbc3-420c-9781-cd801f103b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample_id                                                               16\n",
       "gt_caption_baseline      (A girl with black gloves is running ., Two gi...\n",
       "pred_caption_baseline             A simple scene with a few large regions.\n",
       "bleu1_baseline                                                    0.444444\n",
       "bleu2_baseline                                                    0.074536\n",
       "gt_caption_ai            [A girl with black gloves is running ., A woma...\n",
       "pred_caption_ai                             a woman wearing a purple shirt\n",
       "bleu1_ai                                                          0.833333\n",
       "bleu2_ai                                                           0.57735\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.iloc[idx]['pred_caption_ai']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e488a8-e125-435d-be70-ef4a4041254c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
